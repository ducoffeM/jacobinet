{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061d19d8-022d-4b2c-a81e-afd0adbe7026",
   "metadata": {},
   "source": [
    "# Robust Training with Jacobinet and Adversarial Attacks\n",
    "\n",
    "This tutorial demonstrates the use of Jacobinet for robust training in neural networks. \n",
    "Jacobinet allows the backward pass of a neural network to be represented as a neural network with shared weights. \n",
    "\n",
    "### Goals of this Tutorial ðŸŽ¯\n",
    "\n",
    "* Understand the impact of adversarial attacks on a standard neural network.\n",
    "* Implement robust adversarial training using Jacobinet to generate adversarial examples during the training loop.\n",
    "* Evaluate and compare the robustness of a baseline model and a robustly trained model using the **AutoAttack** benchmark.\n",
    "\n",
    "**Goals:**\n",
    "- Understand adversarial attacks (FGSM, PGD) and their impact on model robustness.\n",
    "- Use Jacobinet to implement robust training by regularizing against adversarial examples.\n",
    "- Evaluate robustness with AutoAttack for both baseline and robust training.\n",
    "\n",
    "We will:\n",
    "1. Train a baseline model and evaluate its adversarial robustness.\n",
    "2. Train a robust model with adversarial regularization using Jacobinet.\n",
    "3. Compare adversarial success rates for both models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4c645-09ce-45d5-8076-5717173444e5",
   "metadata": {},
   "source": [
    "- When running this notebook on Colab, we need to install *jacobinet* if on Colab. \n",
    "- If you run this notebook locally, do it inside the environment in which you [installed *jacobinet*](https://ducoffeM.github.io/jacobinet/main/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759689f7-e1cc-4d59-b730-566d465a895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Colab: install the library\n",
    "on_colab = \"google.colab\" in str(get_ipython())\n",
    "if on_colab:\n",
    "    import sys  # noqa: avoid having this import removed by pycln\n",
    "\n",
    "    # install dev version for dev doc, or release version for release doc\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install git+https://github.com/ducoffeM/jacobinet@main#egg=decomon\n",
    "    # install desired backend (by default torch)\n",
    "    !{sys.executable} -m pip install \"torch\"\n",
    "    !{sys.executable} -m pip install \"keras\"\n",
    "\n",
    "    # extra librabry used in this notebook\n",
    "    !{sys.executable} -m pip install \"torchattacks\"\n",
    "    !{sys.executable} -m pip install \"numpy\"\n",
    "    !{sys.executable} -m pip install \"matplotlib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6889e1-1075-4728-8cc2-2a4dad3e0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this environment variable *before* importing torch, otherwise it has no effect.\n",
    "# Ideally, we'd only set this if torch.backends.mps.is_available() is True,\n",
    "# but checking that requires importing torch first, which would make this setting too late.\n",
    "# So we preemptively enable the MPS fallback just in case MPS is available.\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e9c5e-41db-4741-9b8b-cb8c07044f54",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data\n",
    "\n",
    "We will use the MNIST dataset for this tutorial. The dataset is normalized to the [0, 1] range and reshaped for compatibility with the convolutional model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9b89b-2e2a-4847-95da-3ec3fc7b44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the MNIST data and split it into training and testing sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale the images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape images to have an additional channel dimension (1, 28, 28)\n",
    "x_train = np.expand_dims(x_train, 1)\n",
    "x_test = np.expand_dims(x_test, 1)\n",
    "\n",
    "# Convert class labels to one-hot encoded vectors\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beafcc44-3d81-4d34-836a-a8aa5e0b089c",
   "metadata": {},
   "source": [
    "## Define and Train the Baseline Model\n",
    "\n",
    "We will build a simple Convolutional Neural Network (CNN) using Keras to serve as the baseline model. \n",
    "This model will be trained on MNIST and evaluated for accuracy on clean data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52589ad-076d-4274-98a4-0bb0e013c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, layers\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(1, 28, 28)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"linear\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "train_model = Sequential(model.layers + [layers.Activation(\"softmax\")])\n",
    "\n",
    "train_model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "train_model.fit(x_train, y_train, batch_size=128, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ac9dd-b968-4940-aa8b-94542beb8541",
   "metadata": {},
   "source": [
    "## Evaluate Robustness of Baseline Model\n",
    "\n",
    "We use AutoAttack, a strong adversarial attack framework, to test the baseline model's robustness. \n",
    "AutoAttack generates adversarial examples by varying the attack radius (`epsilon`), and we measure the model's accuracy on these examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a376f-f329-4989-8b1e-cfce6471cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchattacks\n",
    "\n",
    "# Test robustness at different epsilon values\n",
    "n = 20\n",
    "random_index = np.random.permutation(len(x_test))[:n]\n",
    "adv_acc = []\n",
    "eps_values = [np.round(eps_i, 2) for eps_i in np.linspace(0.01, 0.2, 10)]\n",
    "for eps in eps_values:\n",
    "    auto_attack = torchattacks.attacks.autoattack.AutoAttack(model, eps=eps)\n",
    "    adv_data = auto_attack(\n",
    "        torch.Tensor(x_test[random_index]), torch.tensor(y_test[random_index].argmax(-1))\n",
    "    )\n",
    "    acc = (\n",
    "        len(\n",
    "            np.where(\n",
    "                model.predict(adv_data, verbose=0).argmax(-1) != y_test[random_index].argmax(-1)\n",
    "            )[0]\n",
    "        )\n",
    "        / len(random_index)\n",
    "        * 100\n",
    "    )\n",
    "    print(eps, acc)\n",
    "    if len(adv_acc):\n",
    "        adv_acc.append(max(adv_acc[-1], acc))\n",
    "    else:\n",
    "        adv_acc.append(acc)\n",
    "\n",
    "print(acc)\n",
    "\n",
    "plt.plot(eps_values, adv_acc)\n",
    "plt.title(\"Distribution of adversarial success rates with baseline training\")\n",
    "plt.xlabel(\"Epsilon (attack radius)\")\n",
    "plt.ylabel(\"Adversarial success rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb840e45-d931-43b4-a6ca-6ab0252d3833",
   "metadata": {},
   "source": [
    "The plot above shows that the attack success rate quickly climbs to 100% as the attack strength (`epsilon`) increases. \n",
    "This confirms that our baseline model is highly vulnerable to adversarial attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadecfe6-2706-4445-8ac9-8fafabdad8b8",
   "metadata": {},
   "source": [
    "# Robust Training with Jacobinet and Adversarial Attacks\n",
    "\n",
    "To improve robustness, we will train a model that outputs adversarial examples. \n",
    "`Jacobinet` is used to create adversarial examples with Projected Gradient Descent (PGD), which are integrated into the training process.\n",
    "This tutorial demonstrates how to use the **Jacobinet** library to perform robust adversarial training in neural networks. Jacobinet simplifies this process by allowing the backward pass of a neural networkâ€”essential for generating gradient-based adversarial attacksâ€”to be represented as a neural network itself. ðŸ¤–\n",
    "\n",
    "---\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "* **Adversarial Attacks**: These are techniques used to create slightly perturbed inputs (adversarial examples) that are designed to cause a machine learning model to make a mistake. Common attacks include the Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD).\n",
    "* **Adversarial Robustness**: A model is considered robust if it can maintain high accuracy even when evaluated on adversarial examples.\n",
    "* **Adversarial Training**: A method to improve a model's robustness by training it on a mix of clean and adversarial examples. This forces the model to learn features that are less sensitive to small input perturbations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8612c6b-088f-4e8e-a226-2aa3e9057731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jacobinet.attacks import get_adv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75d802-7b28-4f7e-b860-df9509caf926",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_model = get_adv_model(\n",
    "    model, loss=\"categorical_crossentropy\", epsilon=0.2, attack=\"pgd\", n_iter=20, alpha=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c3003-6617-411f-80d6-ed319529924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Input(shape=(1, 28, 28))\n",
    "y = layers.Input((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a8ff9-2045-4cf2-9665-a175ca7da8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = \"./pgd_model.png\"\n",
    "keras.utils.plot_model(pgd_model, to_file=dot_img_file, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from IPython.display import HTML, Image, display\n",
    "\n",
    "display(\n",
    "    HTML('<div style=\"text-align: center;\"><img src=\"{}\" width=\"400\"/></div>'.format(dot_img_file))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49169ffd-a097-4cf4-b611-c028be5c4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adv = keras.models.Model([x, y], model(pgd_model([x, y])))\n",
    "model_adv.compile(\n",
    "    \"adam\",\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3cb0e8-be72-420a-b37b-d3d3da7cb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = \"./model_adv.png\"\n",
    "keras.utils.plot_model(model_adv, to_file=dot_img_file, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from IPython.display import HTML, Image, display\n",
    "\n",
    "display(\n",
    "    HTML('<div style=\"text-align: center;\"><img src=\"{}\" width=\"400\"/></div>'.format(dot_img_file))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a043b14-1f4c-4ea5-b54e-c15e35dd84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adv.fit(\n",
    "    [x_train, y_train],\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=4,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45cefc-caff-4a33-aa0e-7db8fa19fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba4752-0ac8-4693-8c41-10b3f62a9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adv.evaluate([x_test, y_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c5340-0625-41a6-94d1-282367216a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchattacks\n",
    "\n",
    "# Test robustness at different epsilon values\n",
    "adv_acc_baseline = adv_acc  # remember of previous results\n",
    "adv_acc = []\n",
    "eps_values = [np.round(eps_i, 2) for eps_i in np.linspace(0.01, 0.2, 10)]\n",
    "for eps in eps_values:\n",
    "    auto_attack = torchattacks.attacks.autoattack.AutoAttack(model, eps=eps)\n",
    "    # robust to the same set of hyperparameters or to more ???\n",
    "    # auto_attack = torchattacks.attacks.pgd.PGD(model, eps=0.15, alpha=2/255., steps=20, random_start=False)\n",
    "\n",
    "    adv_data = auto_attack(\n",
    "        torch.Tensor(x_test[random_index]), torch.tensor(y_test[random_index].argmax(-1))\n",
    "    )\n",
    "    acc = (\n",
    "        len(\n",
    "            np.where(\n",
    "                model.predict(adv_data, verbose=0).argmax(-1) != y_test[random_index].argmax(-1)\n",
    "            )[0]\n",
    "        )\n",
    "        / len(random_index)\n",
    "        * 100\n",
    "    )\n",
    "    print(eps, acc)\n",
    "    if len(adv_acc):\n",
    "        adv_acc.append(max(adv_acc[-1], acc))\n",
    "    else:\n",
    "        adv_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4208a07-cfdb-436e-8996-889c32c37d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eps_values, adv_acc_baseline)\n",
    "plt.plot(eps_values, adv_acc)\n",
    "plt.title(\"Distribution of adversarial success rates with baseline training\")\n",
    "plt.xlabel(\"Epsilon (attack radius)\")\n",
    "plt.ylabel(\"Adversarial success rate\")\n",
    "plt.legend([\"baseline training\", \"DART training\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ded3bf-37ad-41ae-98c5-105d968eeef0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this tutorial, we demonstrated the effectiveness of adversarial training for improving model robustness. Key takeaways include:\n",
    "\n",
    "1. Baseline models are highly vulnerable to adversarial examples, with attack success rates reaching 100% even for small perturbations.\n",
    "\n",
    "2. Adversarial training significantly improves robustness. By training the model to correctly classify adversarial examples, we made it much more resistant to attacks.\n",
    "\n",
    "3. Jacobinet simplifies robust training. By providing a Keras model that encapsulates the attack generation process, Jacobinet allows adversarial training to be implemented with standard Keras fit() calls, abstracting away the complexities of the backward pass and gradient manipulation.\n",
    "\n",
    "Jacobinet's ability to represent the backward pass as a neural network opens up exciting possibilities for research in robustness, explainability, and the broader field of adversarial machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1faf931-a5fb-4171-9be4-60298b3fe38b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
