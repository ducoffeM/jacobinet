{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03caa8d7-1fba-4db4-8474-83ff6d9b93f1",
   "metadata": {},
   "source": [
    "# Estimating the Local Lipschitz Constant of a Neural Network Using Jacobinet\n",
    "\n",
    "## Introduction\n",
    "In this tutorial, we will estimate the local Lipschitz constant of a neural network using the Jacobian matrix and explore how this constant relates to the network's robustness. A neural network's Lipschitz constant bounds the rate at which its outputs can change with respect to small input perturbations. Understanding and controlling this constant is critical for:\n",
    "\n",
    "- Adversarial robustness: Ensuring the network resists small, intentional perturbations.\n",
    "- Stability: Preventing large output changes due to minor input variations.\n",
    "- Generalization: Improving the network's performance on unseen data.\n",
    "\n",
    "We will use the *Jacobinet* library (based on Keras) to calculate the Jacobian and maximize the $L_p$ norm of the gradient \n",
    "to estimate the Lipschitz constant. This provides a lower bound for the Lipschitz constant, a key metric in robustness evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9d1bc-cd94-4598-9317-56a8d7fc5073",
   "metadata": {},
   "source": [
    "# 1. Building the Neural Network\n",
    "We start by defining a simple feedforward neural network with two dense layers and a ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32862aee-ab9e-4710-a266-27ebef4b6181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ReLU1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ReLU1 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242</span> (968.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m242\u001b[0m (968.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242</span> (968.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m242\u001b[0m (968.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "\n",
    "def build_model():\n",
    "    input_ = Input((10,))\n",
    "    x = Dense(10, name='Dense1')(input_)\n",
    "    x = Activation('relu', name='ReLU1')(x)\n",
    "    x = Dense(10)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    output = Dense(2, name='Output')(x)\n",
    "    return Model(input_, output)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ccd29-e091-4ca1-af1f-a80120af8344",
   "metadata": {},
   "source": [
    "## 2. Computing the Jacobian with Jacobinet\n",
    "\n",
    "We will now compute the Jacobian matrix using Jacobinet’s get_backward_model function. \n",
    "This model returns the gradient of each output with respect to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b10cb8-1e66-4fc9-a876-d1bb4a28d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jacobinet\n",
    "from jacobinet import clone_to_backward\n",
    "import numpy as np\n",
    "\n",
    "# Placeholder gradient to compute the Jacobian\n",
    "gradient_placeholder = keras.Variable(np.ones((1, 2)))\n",
    "\n",
    "# Compute backward model for Jacobian calculation\n",
    "backward_model = clone_to_backward(model, gradient=gradient_placeholder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ded535-fbdc-4ec7-9264-91e1c1f93d37",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "The Jacobian represents the gradients of the output w.r.t. the input.\n",
    "get_backward_model builds a model to compute these gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e569615-31c7-4f01-84f1-d3267579f020",
   "metadata": {},
   "source": [
    "# 3. Estimating the Lipschitz Constant\n",
    "To compute the Lipschitz constant, we use the L2 norm (p=2) of the Jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56e0705-cb76-4119-8806-eb96771cecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lipschitz_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lipschitz_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ grad_constant_1     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GradConstant</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ReLU1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_3    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │ grad_constant_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardDense</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ ReLU1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_activatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ backward_dense_3… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardActivatio…</span> │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_4    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ backward_activat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardDense</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_activatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ backward_dense_4… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardActivatio…</span> │                   │            │ Dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_5    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │ backward_activat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardDense</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lipschitz           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ backward_dense_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lipschitz</span>)         │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m110\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ grad_constant_1     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGradConstant\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ReLU1 (\u001b[38;5;33mActivation\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ Dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_3    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │         \u001b[38;5;34m22\u001b[0m │ grad_constant_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBackwardDense\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m110\u001b[0m │ ReLU1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_activatio… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ backward_dense_3… │\n",
       "│ (\u001b[38;5;33mBackwardActivatio…\u001b[0m │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_4    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │        \u001b[38;5;34m110\u001b[0m │ backward_activat… │\n",
       "│ (\u001b[38;5;33mBackwardDense\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_activatio… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ backward_dense_4… │\n",
       "│ (\u001b[38;5;33mBackwardActivatio…\u001b[0m │                   │            │ Dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_5    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │        \u001b[38;5;34m110\u001b[0m │ backward_activat… │\n",
       "│ (\u001b[38;5;33mBackwardDense\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lipschitz           │ (\u001b[38;5;34m1\u001b[0m)               │          \u001b[38;5;34m0\u001b[0m │ backward_dense_5… │\n",
       "│ (\u001b[38;5;33mLipschitz\u001b[0m)         │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242</span> (968.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m242\u001b[0m (968.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242</span> (968.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m242\u001b[0m (968.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jacobinet import get_lipschitz_model\n",
    "\n",
    "# Create a Lipschitz model using the L2 norm (p=2)\n",
    "lipschitz_model = get_lipschitz_model(backward_model, p=2)\n",
    "lipschitz_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00591cc5-212d-4cae-aa52-d42b41819de0",
   "metadata": {},
   "source": [
    "## Visualizing the Model Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42523bc3-fec0-4373-9226-65243e321b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"./model_dense_lipschitz.png\" width=\"400\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import keras.utils\n",
    "from IPython.display import HTML\n",
    "\n",
    "dot_img_file_lipschitz = './model_dense_lipschitz.png'\n",
    "keras.utils.plot_model(lipschitz_model, to_file=dot_img_file_lipschitz, show_shapes=True, show_layer_names=True)\n",
    "HTML('<div style=\"text-align: center;\"><img src=\"{}\" width=\"400\"/></div>'.format(dot_img_file_lipschitz))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed68ea-1c98-45ad-8509-a0191209bb79",
   "metadata": {},
   "source": [
    "# 4. Evaluating the Lipschitz Constant on Random Data\n",
    "We now evaluate the Lipschitz constant using random input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c1266f-272b-4e00-81bb-a7d7cdf883b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lipschitz constant is at least: tensor([0.3400], device='mps:0', grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(np.random.rand(10)[None], dtype='float32') # Generate random input data\n",
    "\n",
    "# Compute the lower bound of the Lipschitz constant\n",
    "lipschitz_constant = lipschitz_model(data)\n",
    "print(f\"The Lipschitz constant is at least: {lipschitz_constant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab1fac6-4294-467e-b6d8-9cfbb35e7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipschitz_threshold = lipschitz_constant[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc9b9d-a47d-4d48-8041-f5522bfd58d5",
   "metadata": {},
   "source": [
    "# 5. Maximizing the Lp Norm with Adversarial Attacks (PGD)\n",
    "We use Projected Gradient Descent (PGD) to iteratively perturb the input and maximize the Lp norm, tightening the lower bound of the Lipschitz constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff20e7f3-17e2-4c04-a1fe-553487c5cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipschitz constant after 10 PGD steps: tensor([0.3400], device='mps:0', grad_fn=<SqrtBackward0>)\n",
      "Lipschitz constant after 20 PGD steps: tensor([0.3400], device='mps:0', grad_fn=<SqrtBackward0>)\n",
      "Lipschitz constant after 40 PGD steps: tensor([0.4505], device='mps:0', grad_fn=<SqrtBackward0>)\n",
      "Lipschitz constant after 100 PGD steps: tensor([0.5222], device='mps:0', grad_fn=<SqrtBackward0>)\n",
      "Lipschitz constant after 200 PGD steps: tensor([0.7852], device='mps:0', grad_fn=<SqrtBackward0>)\n",
      "Lipschitz constant after 1000 PGD steps: tensor([0.7852], device='mps:0', grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchattacks\n",
    "import torch.nn as nn\n",
    "\n",
    "class LipAttack(nn.Module):\n",
    "    def __init__(self, keras_model):\n",
    "        super().__init__()\n",
    "        self.keras_model = keras_model\n",
    "        self.lipschitz_threshold = keras.Variable(lipschitz_threshold.cpu().detach().numpy())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.keras_model(x)\n",
    "        return torch.cat([keras.ops.relu(self.lipschitz_threshold-x), keras.ops.relu(x-self.lipschitz_threshold)], -1)\n",
    "\n",
    "# Wrap lipschitz_model with the attack class\n",
    "torch_lip_model = LipAttack(lipschitz_model)\n",
    "\n",
    "# Apply PGD attack for different iteration steps\n",
    "adv_data = data\n",
    "for steps in [10, 20, 40, 100, 200, 1000]:\n",
    "    lip_attack = torchattacks.PGD(torch_lip_model, eps=10., steps=steps)\n",
    "    adv_data_ = lip_attack(torch.Tensor(adv_data), torch.Tensor([1, 0]))\n",
    "    lipschitz_constant_adv = lipschitz_model(adv_data)\n",
    "\n",
    "    if torch_lip_model(adv_data_).argmax().cpu().detach().numpy()==1:\n",
    "        adv_data = adv_data_\n",
    "        torch_lip_model.lipschitz_threshold.assign(lipschitz_constant_adv[0].cpu().detach().numpy())\n",
    "    print(f\"Lipschitz constant after {steps} PGD steps: {lipschitz_constant_adv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c7650-b23d-457d-b0b2-8ab4bb00cee6",
   "metadata": {},
   "source": [
    "## 6. Theoretical Insights: Why Lipschitz Constant Matters\n",
    "\n",
    "### 1. Adversarial Robustness\n",
    "A smaller Lipschitz constant implies that the network’s output changes less when small perturbations are applied to the input. This makes it more resistant to **adversarial attacks**, where maliciously crafted input perturbations attempt to mislead the model.\n",
    "\n",
    "### 2. Stability and Generalization\n",
    "Networks with lower Lipschitz constants tend to generalize better, as they are less sensitive to noise or variations in input data. This also enhances training stability, as it prevents excessive variations in gradients.\n",
    "\n",
    "### 3. Mathematical Context\n",
    "The Lipschitz constant \\( L \\) is formally defined as:\n",
    "\n",
    "\n",
    "$$L = \\sup_{x \\neq y} \\frac{\\|f(x) - f(y)\\|}{\\|x - y\\|} $$\n",
    "\n",
    "\n",
    "Locally, this can be approximated using the **Jacobian matrix** \\( J(x) \\), which contains all first-order partial derivatives of the network’s outputs with respect to its inputs:\n",
    "\n",
    "$$ L = \\max_{x} \\|J(x)\\|_p $$\n",
    "\n",
    "\n",
    "where \\( \\|J(x)\\|_p \\) is the **Lp norm** of the Jacobian matrix. Maximizing this norm provides a lower bound on the Lipschitz constant, a key metric for evaluating the robustness of the neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1477cb2-48ec-46ba-a8bd-c8188dce6c44",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial, we used Jacobinet to compute a lower bound for the Lipschitz constant by maximizing the Lp norm using adversarial attacks. The Lipschitz constant is a key measure of a network's robustness and generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232fdab-a867-4e79-bf67-f977716f0f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
