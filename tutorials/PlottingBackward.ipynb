{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c42a5b9-00fb-4b5f-8be0-50cb6efb431b",
   "metadata": {},
   "source": [
    "# Jacobinet Tutorial: Computing and Visualizing Gradients Using Backward Models in Keras\n",
    "\n",
    "In this tutorial, we'll build a simple neural network in Keras and then use the *Jacobinet* library to compute the gradient (Jacobian) of the output with respect to the input. We'll visualize both the forward and backward models and explore how the chain rule applies.\n",
    "\n",
    "## Step 1: Define the Forward Model\n",
    "\n",
    "We'll create a simple feedforward neural network with the following architecture:\n",
    "- Dense Layer (10 units) + ReLU activation\n",
    "- Dense Layer (1 unit) - Output layer\n",
    "\n",
    "The model takes a single input of shape `(1,)` and outputs a single value.\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "\n",
    "# Build the forward model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(10, input_shape=(1,), name='Dense1'),\n",
    "        Activation('relu', name='ReLU1'),\n",
    "        Dense(1, name='Output'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(\"### Forward Model Summary\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d049cdb-8ea2-441b-bc1d-0bc82a6de1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Forward Model Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ducoffe_m/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ReLU1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ReLU1 (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> (248.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62\u001b[0m (248.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> (248.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62\u001b[0m (248.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(10, input_shape=(3,), name='Dense1'),\n",
    "        Activation('relu', name='ReLU1'),\n",
    "        Dense(2, name='Output'),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "model(Input((3,)))\n",
    "\n",
    "# Display model summary\n",
    "print(\"### Forward Model Summary\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bad2b7-11f1-47fe-94fa-b0421a606f17",
   "metadata": {},
   "source": [
    "## Visualize the forward model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81ba7d1-1e89-4b31-95f4-b7388946f090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"./model_dense.png\" width=\"400\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dot_img_file = './model_dense.png'\n",
    "keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "display(HTML('<div style=\"text-align: center;\"><img src=\"{}\" width=\"400\"/></div>'.format(dot_img_file)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c14446-db34-4489-b888-01a3f27fe991",
   "metadata": {},
   "source": [
    "# Step 2: Compute the Backward Model Using JacoBinet\n",
    "\n",
    "*Jacobinet* allows us to compute a backward model that represents the gradient of the output with respect to the input. This is key to understanding the chain rule in neural networks, which is fundamental in backpropagation.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d898a-8480-441a-99eb-bae8c2d797e2",
   "metadata": {},
   "source": [
    "## Import JacoBinet library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393d4d4a-aa3f-4989-8ee6-3b673cba7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jacobinet\n",
    "from jacobinet import clone_to_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67409b0-3fef-40f0-9c64-f4c60c0c3bec",
   "metadata": {},
   "source": [
    "## Get the backward model using JacoBinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e101b5c1-2f9e-4759-99e3-4a74c9cf9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_model = clone_to_backward(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e194b77-93fd-4530-a9d0-3b7e08843cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BackwardModel name=backward_model, built=True>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4260f5-a7c2-43c2-b0ac-e5f1c816d14c",
   "metadata": {},
   "source": [
    "## Display backward model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1af77554-e243-457b-856c-d8efd7c89533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Backward Model Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"backward_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"backward_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_1    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardDense</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_activation │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ backward_dense_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardActivatio…</span> │                   │            │ Dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │ backward_activat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BackwardDense</span>)     │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense_1    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │         \u001b[38;5;34m22\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBackwardDense\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m40\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_activation │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ backward_dense_1… │\n",
       "│ (\u001b[38;5;33mBackwardActivatio…\u001b[0m │                   │            │ Dense1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ backward_dense      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)            │         \u001b[38;5;34m40\u001b[0m │ backward_activat… │\n",
       "│ (\u001b[38;5;33mBackwardDense\u001b[0m)     │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> (248.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62\u001b[0m (248.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> (248.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62\u001b[0m (248.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"### Backward Model Summary\")\n",
    "backward_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cca506-dca3-4b9f-8f49-adf1b7395ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"text-align: center;\"><img src=\"./model_dense_backward.png\" width=\"800\"/></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dot_img_file_backward = './model_dense_backward.png'\n",
    "keras.utils.plot_model(backward_model, to_file=dot_img_file_backward, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "display(HTML('<div style=\"text-align: center;\"><img src=\"{}\" width=\"800\"/></div>'.format(dot_img_file_backward)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab2729e-c31e-412c-bcee-35ee2b59f4ef",
   "metadata": {},
   "source": [
    "## Step 3: Understanding the Chain Rule in Neural Networks\n",
    "\n",
    "In a neural network, the **chain rule** is fundamental for propagating gradients backward, from the output layer to the input layer. It allows us to compute the gradient of the loss with respect to each parameter by combining partial derivatives at each layer. Specifically, The gradient given the input  can be split using the chain rule along any latent dimension *h* given the following expression:\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial L}{\\partial x_i} = \\frac{\\partial L}{\\partial h} \\cdot \\frac{\\partial h}{\\partial x_i} \n",
    "$$\n",
    "\n",
    "In this tutorial, the loss function is simply the identity function applied to the single output of the network, meaning the output itself acts as the loss $ L(y) = y$. This simplification helps illustrate how the gradients flow through the network without additional complexity from the loss computation itself.\n",
    "\n",
    "\n",
    "- $\\frac{\\partial L}{\\partial x_i}$: Gradient of the loss \\(L\\) with respect to the input \\(x_i\\).\n",
    "- $\\frac{\\partial L}{\\partial h} $: Gradient of the loss with respect to a latent dimension \\(h\\).\n",
    "- $\\frac{\\partial h}{\\partial x_i}$: Gradient of the latent ouput \\(h\\) with respect to the input \\(x_i\\).\n",
    "\n",
    "### How the Backward Model Works\n",
    "\n",
    "The **backward model** computes the **Jacobian matrix**, which represents all the partial derivatives of the output with respect to the input. This is crucial in backpropagation since it helps propagate the gradients back through the network.\n",
    "\n",
    "In simpler terms, backpropagation computes how much the network's input contributed to the final loss by applying the chain rule across all layers.\n",
    "\n",
    "### Visualizing the Flow of Gradients\n",
    "\n",
    "The forward model computes the predictions. The backward model, on the other hand, tells us how sensitive the output is to changes in the input by tracing gradients backward through the layers.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Using the Jacobinet library, we have successfully visualized the backward propagation model. This backward model helps us understand how gradients flow through the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2ac58-b3cf-4a67-8735-3b9a0db02f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62370c81-c188-49ba-9d1e-73fe2525eea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
